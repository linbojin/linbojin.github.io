<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="hadoop," />








  <link rel="shortcut icon" type="image/x-icon" href="/rainbow-icon-l.ico?v=0.5.0" />






<meta name="description" content="— HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware. —
The design of HDFSFilesystems that manage the storage acr">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem">
<meta property="og:url" content="https://linbojin.github.io/2016/03/23/Hadoop-Guide-Chapter-3-HDFS/index.html">
<meta property="og:site_name" content="AILab">
<meta property="og:description" content="— HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware. —
The design of HDFSFilesystems that manage the storage acr">
<meta property="og:image" content="https://linbojin.github.io/media/Screen%20Shot%202016-03-28%20at%2016.03.25.png">
<meta property="og:image" content="https://linbojin.github.io/media/Screen%20Shot%202016-03-28%20at%2017.22.01.png">
<meta property="og:image" content="https://linbojin.github.io/media/Screen%20Shot%202016-03-28%20at%2017.22.14.png">
<meta property="og:updated_time" content="2016-04-01T07:30:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem">
<meta name="twitter:description" content="— HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware. —
The design of HDFSFilesystems that manage the storage acr">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem | AILab </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">AILab</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-03-23T15:22:48+08:00" content="2016-03-23">
              2016-03-23
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/03/23/Hadoop-Guide-Chapter-3-HDFS/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/03/23/Hadoop-Guide-Chapter-3-HDFS/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>— <strong><em>HDFS is a filesystem designed for storing very large files with streaming data access patterns, running on clusters of commodity hardware.</em></strong> —</p>
<h3 id="The_design_of_HDFS"><a href="#The_design_of_HDFS" class="headerlink" title="The design of HDFS"></a>The design of HDFS</h3><p>Filesystems that <strong>manage the storage across a network of machines</strong> are called <strong>distributed filesystems</strong>. One of the biggest challenges is making the distributed filesystem <strong>tolerate node failure without suffering data loss</strong>. The hadoop distributed filesystem is called <strong><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html" target="_blank" rel="external">HDFS</a></strong>, which stands for Hadoop Distributed Filesystem.<a id="more"></a> HDFS is a filesystem designed for <strong>storing very large files</strong> with <strong>streaming data access patterns</strong>, running on <strong>clusters of commodity hardware</strong>.</p>
<p>HDFS is built around the idea that the most efficient data processing parttern is <strong>write-once, read-many-times pattern</strong>. Because the namenode holds filesystem metadata in memory, <strong>the limit to the number of files in a filesystem is governed by the amount of memory on the namenode</strong>. As a rule of thumb, each file, directory, and block takes about 150 bytes. So, for example, if you had one million files, each taking one block, you would need at least 300 MB of memory.</p>
<p>Files in HDFS may be written to by a single writer. Writers are always made <strong>at the end of the file, in append-only fashion</strong>.</p>
<h3 id="HDFS_Concepts"><a href="#HDFS_Concepts" class="headerlink" title="HDFS Concepts"></a>HDFS Concepts</h3><h4 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h4><p>A disk has a <strong>block size</strong>, which is <strong>the minimum amount of data that it can read or write</strong>. Filesystems for a single disk build on this by dealing with data in blocks, which are <strong>an integral multiple of the disk block size</strong>. Filesystem blocks are typically a few <strong>kilobytes in size</strong>, whereas disk blocks are <strong>normally 512 bytes</strong>.</p>
<p>Like in a filesystem for a single disk, <strong>files in HDFS are broken into block-sized chunks</strong>, which are <strong>stored as independent units</strong>. <strong>Unlike a filesystem for a single disk, a file in HDFS that is smaller than a single block does not occupy a full block’s worth of underlying storage</strong>.</p>
<p>HDFS has a much larger unit - <strong>128 MB</strong> by default. Why is a block in HDFS so large? The reason is to <strong>minimize the cost of seeks</strong>. If the block is large enough, <strong>the time it takes to transfer the data from the disk can be significantly longer than the time to seek to the start of the block</strong>. This argument shouldn’t be taken too far, however. Map tasks in MapReduce normally <strong>operate on one block at a time</strong>, so if you have too few tasks(fewer than nodes in the cluster), your jobs will run slower than they could oterwise.</p>
<p><strong>There’s nothing that requires the blocks from a file to be stored on the same disk, so they can take advantage of any of the disks in the cluster.</strong> In fact, it would be possible, if unusual, to store a single file on an HDFS cluster whose blocks filled all the disks in the cluster. </p>
<p><strong>Having a block abstraction for a distributed filesystem brings several benefits</strong>:</p>
<ul>
<li>A file can be larger than any single disk in the network.</li>
<li>Making the unit of abstraction a block rather than a file simplifies the storage subsystem. So the storage subsystem only deals with blocks, simplifying storage management: blocks are a fixed size.</li>
<li>Furthermore, blocks fit well with replication for proiding fault tolerance and availability.</li>
</ul>
<p>If <strong>a block becomes unavailable, a copy can be read from another location in a way that is transparent to the client</strong>. A block that is no longer available due to corruption or machine failure <strong>can be replicated from its alternative locations to other live machines to bring the replication factor back to the normal level,</strong> which is callled <strong>Data Integrity</strong> on guarding against corrupt data. </p>
<p>Some applications can <strong>choose to set a high replication factor for the blocks in a popular file to spread the read load on the cluster</strong>. </p>
<p>Command to list the blocks that make up each file in HDFS:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs fsck &lt;path&gt; -files -blocks</span><br></pre></td></tr></table></figure>
<h4 id="Namenodes_and_Datanodes"><a href="#Namenodes_and_Datanodes" class="headerlink" title="Namenodes and Datanodes"></a>Namenodes and Datanodes</h4><p>An HDFS cluster has two types of nodes: <strong>a namenode and a number of datanodes</strong>.</p>
<p>The namenode <strong>manages the filesystem namespace</strong>. It maintains the <strong>filesystem tree and the metadata</strong> for all the files and directories. This information is stored persistently on the local disk in the form of two files: <strong>the namespace image and the edit log</strong>. The namenode also <strong>knows the datanodes on which all the blocks for a given file are located</strong>; however, it <strong>does not store block locations</strong> persistently, which will be reconstructed from datanodes when the system starts. The block mappings are stored in a namenode’s memory, and not on disk.</p>
<p>Datanodes are the workhorses of the filesystem. They will <strong>report back to the namenode periodically with lists of blocks that they are storing</strong>.</p>
<p>If the namenode failed, <strong>all the files on the filesystem would be lost since there would be no way of knowing how to reconstruct the files from the blocks</strong> on the datanodes.</p>
<p>Hadoop provides two mechanisms to make the namenode resilient to failure.:</p>
<ul>
<li><strong>Back up the files</strong> that make up the persistent state of the filesystem metadata. Hadoop can <strong>be configured so that the namenode writes its persistent state to multiple filesystems</strong> (local disk or remote NFS mount). These writes are synchronous and atomic.</li>
<li>Run a <strong>secondary namenode</strong> which <strong>does not act as a namdenode</strong>. <strong>Its main role is to periodically merge the namespace image with edit log to prevent the edit log from becoming too large.</strong> The secondary namenode usually <strong>runs on a separate physical machine</strong> because it requires plenty of CPU and as much memory as the namenode to perform merge. It <strong>keeps a copy of the merged namespace image</strong>, which can be used in the event of the namenode failing. However, <strong>the state of the secondary namenode lags that of the primary</strong>, so in the event of total failure of the primary, <strong>data loss is almost certain</strong>. The usual course of action in this case is to copy the namenode’s metadata files that are on NFS to the secondary and run it as the new primary. </li>
<li>For <strong>High Availability</strong>, it is possible to run a <strong>hot standby namenode</strong> instead of a secondary.</li>
</ul>
<h4 id="Block_Caching"><a href="#Block_Caching" class="headerlink" title="Block Caching"></a>Block Caching</h4><p>Normally a datanode reads blocks from disk, but for <strong>frequently accessed files </strong>the blocks may be <strong>explicitly cached in the datanode’s memory</strong>, in an <strong>off-heap block cache</strong>.</p>
<h3 id="The_Command-Line_Interface"><a href="#The_Command-Line_Interface" class="headerlink" title="The Command-Line Interface"></a>The Command-Line Interface</h3><p>By defalut, HDFS will replicate each filesystem block into <strong>3 replications</strong>. When running with a single datanode, HDFS can’t replicate blocks to three datanodes, so it would <strong>perpetually warn about blocks being under-replicated</strong>.<br>Let’s create a directory first just to see how it is displayed in the listing: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -mkdir books</span><br><span class="line">$ hdfs dfs -ls .</span><br><span class="line"></span><br><span class="line">output</span><br><span class="line">(file mode) (replication)</span><br><span class="line">drwxr-xr-x   - root supergroup    <span class="number">0</span> <span class="number">2016</span>-<span class="number">03</span>-<span class="number">16</span> <span class="number">13</span>:<span class="number">22</span> books</span><br><span class="line">-rw-r--r--   <span class="number">1</span> root supergroup  <span class="number">119</span> <span class="number">2016</span>-<span class="number">03</span>-<span class="number">16</span> <span class="number">13</span>:<span class="number">21</span> test.txt</span><br></pre></td></tr></table></figure>
<p>The entry in replication column is empty for directories because the concept of replication does not apply to them — <strong>directories are treated as metadata and stored by the namenode, not the datanodes</strong>. </p>
<p>File Permissions in HDFS<br>There are tree types of permission in HDFS:</p>
<ul>
<li>The read permission (r) is required to read files or list the contents of a directory. </li>
<li>The write permission (w) is required to write a file or, for a directory, to create or delete files or directories in it. </li>
<li>The execute permission (x) is ignored for a file because you can’t execute a file on HDFS (unlike POSIX), and for a directory this permission is required to access its children. </li>
</ul>
<p>Each file and directory has <strong>an owner, a group, and a mode</strong>. The mode (e.g. <code>drwxr-xr-x</code>) is made up of </p>
<ul>
<li><code>d</code> for dir or <code>-</code> for files</li>
<li>the permissions for the user who is the owner</li>
<li>the permissions for the users who are members of the group</li>
<li>the permissions for users who are neither the owners nor members of the group. </li>
</ul>
<p>By default, Hadoop <strong>runs with security disabled</strong>, which means that a client’s identity is not authenticated. There is a concept of a superuser, which is the identity of the namenode process. Permissions checks are not performed for the superuser.</p>
<h3 id="Hadoop_Filesystems"><a href="#Hadoop_Filesystems" class="headerlink" title="Hadoop Filesystems"></a>Hadoop Filesystems</h3><p>Hadoop has an <strong>abstract notion of filesystems</strong>, of which HDFS is just one implementation. The Java abstract class <strong>org.apache.hadoop.fs.FileSystem</strong> represents the client interface to a filesystem in Hadoop, and there are several concrete implementations:<br><img src="/media/Screen%20Shot%202016-03-28%20at%2016.03.25.png" alt="Hadoop Filesystems"><br>Hadoop provides many interfaces to its filesystems, and it generally uses the <strong>URI scheme to pick the correct filesystem instance</strong> to communicate with </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -ls file:///</span><br><span class="line">$ hadoop fs -ls hdfs://localhost:<span class="number">9000</span>/</span><br></pre></td></tr></table></figure>
<h4 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h4><p>Hadoop is written in Java, so most Hadoop filesystem interactions are mediated through the Java API. The <strong>filesystem shell</strong>, for example, is a Java application that uses the Java <code>FileSystem</code> class to provide filesystem operations. Here are two commonly used other filesystem interfaces with HDFS:</p>
<ul>
<li><p>NFS<br>  It is possible to <strong>mount HDFS on a local client’s filesystem</strong> using Hadoop’s <strong>NFSv3 gateway</strong>. You can then <strong>use Unix utilities</strong> (such as <code>ls</code> and <code>cat</code>) to <strong>interact with the filesystem</strong>, upload files, and in general use POSIX libraries to access the filesystem from any programming language. <strong>Appending to a file works, but random modifications of a file do not, since HDFS can only write to the end of a file</strong>.</p>
</li>
<li><p>FUSE<br>  Filesystem in Userspace (FUSE) allows filesystems that are implemented in user space to be integrated as Unix filesystems. Hadoop’s Fuse-DFS contrib module allows HDFS (or any Hadoop filesystem) to be mounted as a standard local filesystem. Fuse-DFS is implemented in C using libhdfs as the interface to HDFS. At the time of writing, the Hadoop NFS gateway is the more robust solution to mounting HDFS, so should be preferred over Fuse-DFS. </p>
</li>
</ul>
<h3 id="Data_Flow"><a href="#Data_Flow" class="headerlink" title="Data Flow"></a>Data Flow</h3><h4 id="File_Read"><a href="#File_Read" class="headerlink" title="File Read"></a>File Read</h4><p>The image shows the main sequence of events when reading a file from HDFS cluster.<br><img src="/media/Screen%20Shot%202016-03-28%20at%2017.22.01.png" alt="Anatomy of a File Read"></p>
<h4 id="File_Write"><a href="#File_Write" class="headerlink" title="File Write"></a>File Write</h4><p>The image shows the main sequence of events when writing a file to HDFS cluster.<br><img src="/media/Screen%20Shot%202016-03-28%20at%2017.22.14.png" alt="Anatomy of a File Write"></p>
<h3 id="Parallel_copying_across_clusters_with_distcp"><a href="#Parallel_copying_across_clusters_with_distcp" class="headerlink" title="Parallel copying across clusters with distcp"></a>Parallel copying across clusters with distcp</h3><p>The HDFS access patterns that we have seen so far focus on <strong>single-threaded access</strong>. It’s possible to act on a collection of files. Hadoop comes with a useful program called <code>distcp</code> for copying data to and from Hadoop filesystems <strong>in parallel</strong>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop distcp file1 file2      <span class="comment"># same to hadoop fs -cp file1 file2</span></span><br><span class="line">$ hadoop distcp dir1 dir2        <span class="comment"># If dir2 exists, new structure will be dir2/dir1 </span></span><br><span class="line">$ hadoop distcp -overwrite dir1 dir2    <span class="comment"># dir2 will be overwritten</span></span><br><span class="line">$ hadoop distcp -update dir1 dir2       <span class="comment"># synchronize the change with dir2</span></span><br></pre></td></tr></table></figure>
<p><code>distcp</code> is implemented <strong>as a MapReduce job</strong> where the work of copying is done <strong>by the maps that run in parallel across the cluster</strong>. Each file is copied by a single map, and distcp tries to give each map approximately the same amount of data by bucketing files into roughly equal allocations. By default, up to <strong>20 maps are used</strong>, but this can be changed by specifying the <code>-m</code> argument to distcp.<br>A very common use case for distcp is for <strong>transferring data between two HDFS clusters</strong>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -delete: delete any files or directories from the destination </span></span><br><span class="line"><span class="comment">#          that are not present in the source </span></span><br><span class="line"><span class="comment"># -p:      file status attributes like permissions, block size, </span></span><br><span class="line"><span class="comment">#          and replication are preserved </span></span><br><span class="line">$ hadoop distcp -update -delete -p hdfs://namenode1/foo hdfs://namenode2/foo</span><br></pre></td></tr></table></figure>
<h4 id="Keeping_an_HDFS_Cluster_Balanced"><a href="#Keeping_an_HDFS_Cluster_Balanced" class="headerlink" title="Keeping an HDFS Cluster Balanced"></a>Keeping an HDFS Cluster Balanced</h4><p>When copying data into HDFS, it’s important to consider cluster balance. <strong>HDFS works best when the file blocks are evenly spread across the cluster</strong>, so you want to ensure that distcp doesn’t disrupt this. For example, if you specified -m 1, a single map would do the copy, which results that the first replica of each block would reside on the node running the map (until the disk filled up). So it’s best to start by running distcp with the default of 20 maps per node. </p>
<p>However, you can also use the <strong>balancer tool</strong> (known as <strong><a href="http://www.cloudera.com/documentation/archive/cdh/4-x/4-7-1/CDH4-Installation-Guide/cdh4ig_balancer.html" target="_blank" rel="external">Balancer</a></strong>) to subsequently even out the block distribution across the cluster. </p>

      
    </div>

    <div>
      
        
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag">#hadoop</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/03/22/Hadoop-Guide-Chapter-1-Meet-Hadoop/" rel="next" title="Hadoop Guide Chapter 1: Meet Hadoop">
                <i class="fa fa-chevron-left"></i> Hadoop Guide Chapter 1: Meet Hadoop
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/04/01/Setup-Vim-as-an-IDE/" rel="prev" title="Setup Vim as an IDE">
                Setup Vim as an IDE <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <div class="ds-share flat" data-thread-key="2016/03/23/Hadoop-Guide-Chapter-3-HDFS/"
     data-title="Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem"
     data-content=""
     data-url="https://linbojin.github.io/2016/03/23/Hadoop-Guide-Chapter-3-HDFS/">
  <div class="ds-share-inline">
    <ul  class="ds-share-icons-16">

      <li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
      <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
      <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
      <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
      <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>

    </ul>
    <div class="ds-share-icons-more">
    </div>
  </div>
</div>
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/03/23/Hadoop-Guide-Chapter-3-HDFS/"
           data-title="Hadoop Guide Chapter 3: The Hadoop Distributed Filesystem" data-url="https://linbojin.github.io/2016/03/23/Hadoop-Guide-Chapter-3-HDFS/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars1.githubusercontent.com/u/5894707?v=3&s=460"
               alt="Linbo.me" />
          <p class="site-author-name" itemprop="name">Linbo.me</p>
          <p class="site-description motion-element" itemprop="description">Linbo's Blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>
          
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/linbojin" target="_blank">
                  
                    <i class="fa fa-github"></i> GitHub
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1882763701" target="_blank">
                  
                    <i class="fa fa-weibo"></i> Weibo
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://linkedin.com/in/linbojin" target="_blank">
                  
                    <i class="fa fa-linkedin-square"></i> LinkedIn
                  
                </a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
            <p class="site-author-name">Links</p>
            
              <span class="links-of-author-item">
                <a href="https://databricks.com/blog" target="_blank">Databricks Blog</a>
              </span>
            
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#The_design_of_HDFS"><span class="nav-number">1.</span> <span class="nav-text">The design of HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS_Concepts"><span class="nav-number">2.</span> <span class="nav-text">HDFS Concepts</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Blocks"><span class="nav-number">2.1.</span> <span class="nav-text">Blocks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Namenodes_and_Datanodes"><span class="nav-number">2.2.</span> <span class="nav-text">Namenodes and Datanodes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Block_Caching"><span class="nav-number">2.3.</span> <span class="nav-text">Block Caching</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The_Command-Line_Interface"><span class="nav-number">3.</span> <span class="nav-text">The Command-Line Interface</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop_Filesystems"><span class="nav-number">4.</span> <span class="nav-text">Hadoop Filesystems</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Interfaces"><span class="nav-number">4.1.</span> <span class="nav-text">Interfaces</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data_Flow"><span class="nav-number">5.</span> <span class="nav-text">Data Flow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#File_Read"><span class="nav-number">5.1.</span> <span class="nav-text">File Read</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#File_Write"><span class="nav-number">5.2.</span> <span class="nav-text">File Write</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Parallel_copying_across_clusters_with_distcp"><span class="nav-number">6.</span> <span class="nav-text">Parallel copying across clusters with distcp</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Keeping_an_HDFS_Cluster_Balanced"><span class="nav-number">6.1.</span> <span class="nav-text">Keeping an HDFS Cluster Balanced</span></a></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linbo.me</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.scheme !== 'Pisces' && (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always')) {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"ailab"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

  
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  


</body>
</html>
